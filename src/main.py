import asyncio
import json

import aioredis
from loguru import logger

from handlers.handlers_init import register_handlers
from settings import settings
from utils.redis_utils import cleanup_dlq, mark_task_failed, recover_tasks

logger.add('worker.log', level=settings.LOGLEVEL, rotation='10 MB')


async def main():

    if len(task_handlers) - 1 == 0:  # -1 for dummy handler
        logger.error('‚ùå –î–æ—Å—Ç—É–ø–µ–Ω —Ç–æ–ª—å–∫–æ dummy –æ–±—Ä–∞–±–æ—Ç—á–∏–∫!')
    elif not task_handlers:
        error_msg = '‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤ –∑–∞–¥–∞—á!'
        logger.error(error_msg)
        raise RuntimeError(error_msg)

    asyncio.create_task(cleanup_dlq(redis))
    try:
        await __worker_loop()
    finally:
        await redis.close()


async def __worker_loop():

    await recover_tasks(redis)

    while True:
        try:
            task_id = await redis.brpoplpush(
                'task_queue', 'processing_queue', timeout=0)
            logger.info(f'üì• –ü–æ–ª—É—á–µ–Ω–∞ –∑–∞–¥–∞—á–∞: {task_id}')
            await __process_task(task_id)

        except Exception as e:
            logger.error(f'‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ worker: {e}')
            await asyncio.sleep(1)


async def __process_task(task_id: str):
    """Handle task"""

    try:
        task_data = await redis.get(f'task:{task_id}')
        if not task_data:
            raise RuntimeError(f'‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞')
        task: dict = json.loads(task_data)
        handler = await __get_handler(task, task_id)

    except Exception as e:
        logger.warning(str(e))
        await mark_task_failed(redis, task_id, str(e))
        raise

    try:
        prompt = task['prompt']
        logger.debug(f'üß† –ü–æ–ª—É—á–µ–Ω prompt: {prompt}')

        result = await handler(task)
        logger.debug(f'üß† –†–µ–∑—É–ª—å—Ç–∞—Ç: {result}')

        task['status'] = 'completed'
        task['result'] = result
        await redis.setex(f'task:{task_id}', 86400, json.dumps(task))
        await redis.lrem('processing_queue', 1, task_id)
        logger.info(f'‚úÖ –ó–∞–¥–∞—á–∞ {task_id} –≤—ã–ø–æ–ª–Ω–µ–Ω–∞')

    except Exception as e:
        logger.error(f'‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏ {task_id}: {str(e)}')
        retries = await redis.hincrby(f'task:{task_id}', 'retries', 1)
        if retries > 3:
            await redis.rpush('dead_letters', task_id)
            await redis.lrem('processing_queue', 1, task_id)
            await mark_task_failed(
                redis, task_id, '‚ö†Ô∏è –ü—Ä–µ–≤—ã—à–µ–Ω–æ —á–∏—Å–ª–æ –ø–æ–ø—ã—Ç–æ–∫')
        else:
            await redis.lrem('processing_queue', 1, task_id)
            await redis.rpush('task_queue', task_id)
        raise


async def __get_handler(task, task_id):
    task_type = task['task_type']
    handler = task_handlers.get(task_type)

    if not handler:
        raise KeyError(f'‚ö†Ô∏è –ó–∞–¥–∞—á–∞ {task_id} –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞, —Ç–∏–ø '
                       f'–∑–∞–¥–∞—á–∏ {task_type} –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è')
    return handler


if __name__ == '__main__':
    redis = aioredis.Redis.from_url(
        f'redis://{settings.HOST}:{settings.REDIS_PORT}/{settings.REDIS_DB}',
        decode_responses=True
    )
    task_handlers = asyncio.run(register_handlers())
    asyncio.run(main())
